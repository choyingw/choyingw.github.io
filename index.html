<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Cho-Ying Wu, wuchoying, choying wu, Wu choying, Choying, CS, PhD, USC, The University of Southern California"> 
<meta name="description" content="profile">

<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Cho-Ying Wu</title>
<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
-->
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="Arial"> Cho-Ying Wu </font></h1>
				</div>

				<h3><font face="Arial"> Ph.D. Candidate </font></h3>
				<p><font face="Arial"> 
					Rm 108, Powell Hall, <br>
					Department of Computer Science, <br>
					University of Southern California, <br>
					Los Angeles, CA. <br>
					<br>
					<em>Email: <a href="mailto:choyingw@usc.edu">choyingw@usc.edu</a></em> <br>
					<a href="supp/CV.pdf"><em>[CV]</em></a>
					<footer class="site-footer">
						<div class="wrapper">
							<div class="footer-col">
							<a href="https://github.com/choyingw" target="_blank">
							<img src="images/color-github.png" class="social-icon", width="40" height="40">
							</a>
							<a href="https://twitter.com/ChoYingWu2" target="_blank">
							<img src="images/color-twitter.png" class="social-icon", width="40" height="40">
							</a>
							<a href="https://www.linkedin.com/in/cho-ying-wu-4b3b03175/" target="_blank">
							<img src="images/color-linkedin.png" class="social-icon", width="40" height="40">
							</a>
							<a href="https://scholar.google.com/citations?user=TTDb6YMAAAAJ&hl" target="_blank">
							<img src="images/color-gscholar-footer.png" class="social-icon", width="40" height="40">
							</a>
							</div>
							</div>
						</div>
					</footer>  
				</font></p>
				<!--<p> <a href="https://scholar.google.com/citations?user=tUb4J0kAAAAJ&hl=en"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/xw-hu"><img src="./pic/github_s.jpg" height="20px" style="margin-bottom:-3px"></a>
					<a href="https://www.facebook.com/xiaowei.hu.102"><img src="./pic/Facebook_s.png" height="30px" style="margin-bottom:-3px"></a>
				</p> -->
			</td>
			<td>
				<img src="images/profile.jpg" border="0" width="240"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>


<p style="text-align:justify";><font face="Arial">
	I am a fourth-year Ph.D candidate at <strong>CS Department of <a href="https://www.usc.edu/">Univeristy of Southern California</a> </strong> working with Prof. <a href="https://viterbi.usc.edu/directory/faculty/Neumann/Ulrich"><strong>Ulrich Neumann </strong></a>. Before that, I obtained my MS degree in <a href="https://comm.ntu.edu.tw/en/">Graduate Institute of Communication and Engineering</a> at <a href="https://www.ntu.edu.tw/english/">National Taiwan University</a>. I earned a double major degree from National Taiwan University for <a href="https://web.ee.ntu.edu.tw/eng/index.php">Electrial Engineering</a> and <a href="http://www.law.ntu.edu.tw/index.php/eng">Law</a>. <br><br>
    
    I also passed the <a href="http://www.twba.org.tw/en/Report.htm#c02">Attorney of Higher Examination</a> in Taiwan in 2016. This is equalivent to the bar exam in the United States. <br><br>
	
	My research interests are <strong>3D Vision</strong>, <strong>Depth Sensing</strong>, <strong>3D Face Modeling</strong>. <br><br>

	
    
    <p><strong><font face="Arial", color=#519299> Internship:</font></strong></p>

	<style>
		.ImageHolder{
		text-align:center;
		}

		.Image{
		display:inline-block;
		margin-right: 80px;
		margin-bottom: 5px;
		text-align:center;
		}
	</style>

	<div class="Image">
		<img src="images/Argo_AI.png" , height="120">
		<p> <a href="https://www.argo.ai/">Argo AI</a>, 2019</p>
	</div>
	<div class="Image">
		<img src="images/Amazon_126.png" , height="140">
		<p> <a href="https://amazon.jobs/en">Amazon</a>, 2020</p>
	</div>
	<div class="Image">
		<img src="images/facebook.png" , height="140">
		<p> <a href="https://tech.fb.com/ar-vr/">Facebook</a>, 2021</p>
	</div>
    
</font></p>



<h2><font face="Arial"> News </font></h2>
<ul style="list-style-type:none">
   <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3">
   	  [09/2021] 1 paper "Synergy between 3DMM and 3D Landmarks for Accurate 3D Facial Geometry" accepted to 3DV 2021 <br>
   	  [01/2021] 1 paper "Scene Completeness-Aware Lidar Depth Completion for Driving Scenario" accepted to ICASSP 2021 <br>
   	  [05/2020] 1 paper "Geometry-Aware Instance Segmentation with Disparity Maps" accepted to CVPR 2020 Workshop on Scalability on Autonomous Driving<br>
   	  [05/2020] 1 paper "Grid-GCN for Fast and Scalable Point Cloud Learning" accepted to CVPR 2020 <br>
   	  [09/2019] 1 paper "Efficient Multi-Domain Dictionary Learning with GANs" accepted to GlobalSIP 2019 (Oral) <br>
   	  [09/2019] 1 paper "Deep RGB-D Canonical Correlation Analysis For Sparse Depth Completion" accepted to NeurIPS 2019 <br>
      [05/2019] 1 "Salient Building Outline Enhancement and Extraction Using Iterative L0 Smoothing and Line Enhancing" accepted to ICIP 2019 <br>
      [08/2018] Starting my PhD studies at USC <br>
      [01/2018] 1 paper accepted to Pattern Recognition <br> 
   </font></p>
</ul>



<h2><font face="Arial"> Publications </font></h2>
<ul style="list-style-type:none">

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            <font color = #246B02> <b>Toward Practical Self-Supervised Monocular Indoor Depth Estimation </b></font><br> 
         <i>  <b>Cho-Ying Wu</b>, Jialiang Wang, Michael Hall, Ulrich Neumann, Shuochen Su</i><br> 
	       Preprint, 2021 <br>
	 [<a href="https://arxiv.org/abs/2112.02306">paper</a>]
	 </p> </li>

	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            <font color = #246B02> <b>Voice2Mesh: Cross-Modal 3D Face Model Generation from Voices </b></font><br> 
         <i>  <b>Cho-Ying Wu</b>, Ke Xu, Chin-Cheng Hsu, Ulrich Neumann</i><br> 
	       Preprint, 2021 <br>
	 [<a href="https://arxiv.org/abs/2104.10299">paper</a>]
	 [<a href="https://github.com/choyingw/Voice2Mesh">code</a>]
	 [<a href="works/Voice2Mesh/index.html">project page</a>]<br>
	 <!-- [<a href="https://www.youtube.com/watch?v=FQDTdpMPKxs">Youtube video</a>]<br> -->
	 <i>An anlaysis on the statistical correlation between voices and 3D faces. Unlike previous work using 2D representations that include background or hairstyle variations, our 3D approach better validate correlation between voices and geometry.</i> 
	 </p> </li>

	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>Synergy between 3DMM and 3D Landmarks for Accurate 3D Facial Geometry </b></font><br> 
         <i>  <b>Cho-Ying Wu</b>, Qiangeng Xu, Ulrich Neumann</i><br> 
	       IEEE International Conference on 3D vision (<b>3DV</b>), 2021 <br>
	 [<a href="https://arxiv.org/abs/2104.08403">paper</a>]
	 [<a href="https://github.com/choyingw/SynergyNet">code</a>]
	 [<a href="works/SynergyNet/index.html">project page</a>]
	 [<a href="https://www.youtube.com/watch?v=4cMWdW9IuDU&t=31s">video</a>]
	 [<a href="works/SynergyNet/img/2152-Poster.pdf">poster</a>]<br>
	 <i>This work attains the <b>state of the art</b> on 3D facial geometry prediction, including 3D facial alignment, face orientation estimation, and 3D face modeling.</i> 
	 </p> </li>

	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>Scene Completeness-Aware Lidar Depth Completion for Driving Scenario </b></font><br> 
         <i>  <b>Cho-Ying Wu</b>, Ulrich Neumann</i><br> 
	       IEEE International Conference on Acoustics, Speech, & Signal Processing (<b>ICASSP</b>), 2021 <br>
	 [<a href="https://arxiv.org/abs/2003.06945">paper</a>]
	 [<a href="https://github.com/choyingw/SCADC-DepthCompletion">code</a>]
	 [<a href="works/SCADC/index.html">project page</a>]
	 [<a href="https://www.youtube.com/watch?v=FQDTdpMPKxs">1-min demo</a>]
	 [<a href="https://www.youtube.com/watch?v=IentdAL0Quk">long version video</a>]
	 [<a href="works/SCADC/img/2152-Poster.pdf">poster</a>]
	 [<a href="works/SCADC/img/2152-slides.pdf">slides</a>]<br>
	 <i>This work is the first to attend scene-completeness issue of depth completion. We obtain both structured and accurate scene depth.</i> 
	 </p> </li>

	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>Geometry-Aware Instance Segmentation with Disparity Maps </b></font><br> 
         <i>  <b>Cho-Ying Wu</b>, Xiaoyan Hu, Michael Happold, Qiangeng Xu, Ulrich Neumann</i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition Workshop Scalability in Autonomous Driving (<b>CVPRw</b>), 2020 <br>
	 [<a href="http://www-scf.usc.edu/~choyingw/works/GAIS-Net/WSAD/CVPRW_CameraReady.pdf">paper</a>]
	 [<a href="works/GAIS-Net/index.html">project page</a>]
	 [<a href="https://github.com/choyingw/GAIS-Net">code</a>]
	 [<a href="https://www.youtube.com/watch?v=QmzGAStQXOc">video</a>]<br>
	 <i> The first outdoor instacne segmentation that using disparity maps. Based on Mask-RCNN, we show that using multi-modality of geometric information can improve the performance.</i> 


	 </p> </li>


	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>Grid-GCN for Fast and Scalable Point Cloud Learning </b></font><br> 
         <i>  Qiangeng Xu, Xudong Sun, <b>Cho-Ying Wu</b>, Panqu Wang, Ulrich Neumann</i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020 <br>
	 [<a href="https://arxiv.org/abs/1912.02984">paper</a>]
	 [<a href="https://github.com/ICpachong/Grid-GCN">code</a>]

	 </p> </li>
 
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>Deep RGB-D Canonical Correlation Analysis for Sparse Depth Completion </b></font><br> 
         <i>  <b>Cho-Ying Wu*</b>, Yiqi Zhong*, Suya You, Ulrich Neumann (*Equal Contribution)</i><br> 
	       Neural Information Processing System (<b>NeurIPS</b>), 2019 <br>
	 [<a href="https://arxiv.org/abs/1906.08967">paper</a>]
	 [<a href="https://github.com/choyingw/CFCNet">code</a>]
	 [<a href="https://www.youtube.com/watch?v=6HCWipHkv60">Youtube video</a>]
	 [<a href="works/CFCNet/poster.pdf">poster</a>]<br>
	 <i> We study deep canonical correlation analysis for multi-modal fusion on depth completion and attain the SOTA performance when only few sparse measurements are available.</i> 

	 </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>Salient Building Outline Enhancement and Extraction Using Iterative L0 Smoothing and Line Enhancing </b></font><br> 
         <i>  <b>Cho-Ying Wu</b>, Ulrich Neumann</i><br> 
	       IEEE International Conference on Image Processing (<b>ICIP</b>), 2019 <br>
	 [<a href="https://arxiv.org/abs/1906.02426">paper</a>]
	 [<a href="https://github.com/choyingw/BuildingOutline">code</a>]
	 [<a href="works/Building_Outline/All_GT.zip">groundtruth dataset</a>] 
	 [<a href="extra.html">additional results</a>]<br>
	 <i> Using iterative operation of L0-smoothing and enhancing, we can extract robust outlines for buildings.</i> 

	 </p> </li>

    <!--
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Nonconvex Surrogates for Robust Principal Component Analysis <br> 
         <i>  <b>Cho Ying Wu</b>, Jian Jiun Ding</i><br> 
	       submitted to IEEE International Symposium on Information Theory (<b>ISIT</b>), 2019 <br>
	 [<a href="">paper</a>]
	 [code] (Code will be released after accepted) 
	</p> </li>
	-->

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>Efficient Multi-Domain Dictionary Learning with GANs</b></font><br> 
         <i>   <b>Cho-Ying Wu</b>, Ulrich Neumann </i><br> 
	     IEEE Global Signal and Information Processing, (<b>GlobalSIP</b>), 2019<br> (Oral)
	 [<a href="https://arxiv.org/abs/1811.00274">paper</a>]<br>
	 <i> This work learns multi-domain dictionary from GANs that improve the robustness of dictionary learning.</i> 
	  </font>
	 </p> </li>
	
	<!--
	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Advanced Optimization Approach for Low-Rank Models with Nonconvex Surrogates and Dual Momentum <br> 
         <i>   <b>Cho Ying Wu</b>, Jian Jiun Ding </i><br> 
	     <br>
	 [paper]
	 </font>
	 </p> </li>
	-->

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>Occluded Face Recognition Using Low-rank Regression with Generalized Gradient Direction</b></font><br> 
	 <i>   <b>Cho-Ying Wu</b>, Jian Jiun Ding </i><br> 
             Pattern Recognition (<b>PR</b>), vol. 80, pp. 256â€“268, 2018. (Impact Factor: 5.898)<br>
	 [<a href="https://www.sciencedirect.com/science/article/pii/S0031320318301079">paper</a>]
	 [<a href="works/Face_GDHASLR.zip">code</a>]<br>
	 <i> A robust and efficient occluded face recognition framework that attains the SOTA, using the sparse and low-rank model.</i> 
	 </p> </li>

	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>A Fast Non-convex And Non-smooth Regularizer For Low Rank Matrix Completion</b></font><br> 
	 <i>   <b>Cho-Ying Wu</b>, Jian-Jiun Ding </i><br> 
             Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (<b>APSIPA-ASC</b>), 2017. <br>
	 [<a href="https://ieeexplore.ieee.org/document/8282052">paper</a>]
	 </p> </li>

	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		<font color = #246B02><b>Occlusion Pattern-based Dictionary For Robust Face Recognition</b></font><br> 
	 <i>   <b>Cho-Ying Wu</b>, Jian-Jiun Ding </i><br> 
             IEEE International Conference on Multimedia & Expo (<b>ICME</b>), 2016. <br>
	 [<a href="https://ieeexplore.ieee.org/document/7552982">paper</a>]
	 </p> </li>
	
</ul>


<h2><font face="Arial"> Academic Activities </font></h2>
<ul style="list-style-type:none">
	
	<!-- <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Reviewer </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		 Journal: IEEE Access<br>
		 Conference: ICIP 2019, ICIP 2020, ICIP 2021
	      </font> </p> 
         </li>
	 -->
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Teaching Assistant </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
			Computer Graphics, University of Southern California, Fall 2021<br>
			Database Systems, University of Southern California, Spring 2021<br>
	       Computer Graphics, University of Southern California, Fall 2020<br>
	       Database Systems, University of Southern California, Spring 2020<br>
	       Computer Graphics, University of Southern California, Fall 2019<br>
	       Data Structures and Object Oriented Design, University of Southern California, Spring 2019<br>
	       Advanced Digital Signal Processing, National Taiwan University, Spring 2017 <br>
	       Differential Equation, National Taiwan University, Fall 2016 <br>
	      </font> </p>
	 </li>
	
	
<footer class="site-footer">
<br><br>
<div class="wrapper">
	<div class="footer-col">
	<p>Contacts:</p>
	<a href="https://github.com/choyingw" target="_blank">
	<img src="images/color-github.png" class="social-icon", width="40" height="40">
	</a>



	<a href="https://twitter.com/ChoYingWu2" target="_blank">
	<img src="images/color-twitter.png" class="social-icon", width="40" height="40">
	</a>



	<a href="https://www.linkedin.com/in/cho-ying-wu-4b3b03175/" target="_blank">
	<img src="images/color-linkedin.png" class="social-icon", width="40" height="40">
	</a>



	<a href="https://scholar.google.com/citations?user=TTDb6YMAAAAJ&hl" target="_blank">
	<img src="images/color-gscholar-footer.png" class="social-icon", width="40" height="40">
	</a>


	</div>
	</div>

</div>

</footer>
		
</body></html>

