<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Cho-Ying Wu, wuchoying, choying wu, Wu choying, Choying, CS, PhD, USC, The University of Southern California"> 
<meta name="description" content="profile">

<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Profile of Cho-Ying Wu, University of Southern California</title>
<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
-->
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="Arial"> Cho-Ying Wu </font></h1>
				</div>

				<h3><font face="Arial"> Ph.D. Candidate </font></h3>
				<p><font face="Arial"> 
					Rm 108, Powell Hall, <br>
					Department of Computer Science, <br>
					University of Southern California, <br>
					Los Angeles, CA. <br>
					<br>
					<em>Email: <a href="mailto:choyingw@usc.edu">choyingw@usc.edu</a></em> <br>
					<a href="supp/CV_2020.pdf"><em>[CV]</em></a>  
				</font></p>
				<!--<p> <a href="https://scholar.google.com/citations?user=tUb4J0kAAAAJ&hl=en"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/xw-hu"><img src="./pic/github_s.jpg" height="20px" style="margin-bottom:-3px"></a>
					<a href="https://www.facebook.com/xiaowei.hu.102"><img src="./pic/Facebook_s.png" height="30px" style="margin-bottom:-3px"></a>
				</p> -->
			</td>
			<td>
				<img src="images/profile.jpeg" border="0" width="240"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<br />
<br />

<p style="text-align:justify";><font face="Arial">
	I am currently a third-year Ph.D candidate at  <strong>CS Department of <a href="https://www.usc.edu/">Univeristy of Southern California</a> </strong> working with Prof. <a href="https://viterbi.usc.edu/directory/faculty/Neumann/Ulrich"><strong>Ulrich Neumann </strong></a>. Before that, I obtained my MS degree in <a href="https://comm.ntu.edu.tw/en/">Graduate Institute of Communication and Engineering</a> at <a href="https://www.ntu.edu.tw/english/">National Taiwan University</a>. I graduated from National Taiwan University B.S. 2015 double-majoring in <a href="https://web.ee.ntu.edu.tw/eng/index.php">Electrial Engineering</a> and <a href="http://www.law.ntu.edu.tw/index.php/eng">Law</a>. <br><br>
    
    My research interests are <strong>Computer Vision</strong>, <strong>3D Scene Understanding</strong>, <strong>Singal Processing</strong>, <strong>Compressive Sensing, and Optimization</strong>. <br><br>
    
    Internship Experience: 

    <p> <img src="images/Argo_AI.png" border="0" width="90"> <a href="https://www.argo.ai/">Argo AI</a> May - Aug, 2019</p>
    <p> <img src="images/Amazon_126.png" border="0" width="140"> <a href="https://amazon.jobs/en">Amazon Lab126</a> May - Aug, 2020</p>
    <p> <img src="images/facebook.png" border="0" width="80"> <a href="https://tech.fb.com/ar-vr/">Facebook Reality Labs</a> May - Aug, 2021</p> <br><br>

    I also passed the <a href="http://www.twba.org.tw/en/Report.htm#c02">Attorney of Higher Examination</a> in Taiwan in 2016. This is equalivent to the bar exam in the United States.
</font></p>



<h2><font face="Arial"> News </font></h2>
<ul style="list-style-type:none">
   <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3">
   	  [01/2021] 1 paper "Scene Completeness-Aware Lidar Depth Completion for Driving Scenario" got accepted to ICASSP 2021 <br>
   	  [05/2020] 1 paper "Geometry-Aware Instance Segmentation with Disparity Maps" got accepted to CVPR 2020 Workshop on Scalability on Autonomous Driving<br>
   	  [05/2020] 1 paper "Grid-GCN for Fast and Scalable Point Cloud Learning" got accepted to CVPR 2020 <br>
   	  [09/2019] 1 paper "Efficient Multi-Domain Dictionary Learning with GANs" got accepted to GlobalSIP 2019 (Oral) <br>
   	  [09/2019] 1 paper "Deep RGB-D Canonical Correlation Analysis For Sparse Depth Completion" got accepted to NeurIPS 2019 <br>
      [05/2019] 1 "Salient Building Outline Enhancement and Extraction Using Iterative L0 Smoothing and Line Enhancing" got accepted to ICIP 2019 <br>
      [08/2018] Starting my PhD studies at USC <br>
      [01/2018] 1 paper accepted to Pattern Recognition <br> 
   </font></p>
</ul>



<h2><font face="Arial"> Publications </font></h2>
<p><font face="Arial"><a href="https://scholar.google.com/citations?user=TTDb6YMAAAAJ&hl=en">Google Scholar</a></font></p>
<ul style="list-style-type:none">

	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Accurate 3D Facial Geometry Prediction by Multi-Task, Multi-Modal, and Multi-Representation Landmark Refinement Network <br> 
         <i>  <b>Cho-Ying Wu</b>, Qiangeng Xu, Ulrich Neumann</i><br> 
	       Preprint, 2021 <br>
	 [<a href="https://arxiv.org/abs/2003.06945">paper</a>]
	 [<a href="https://github.com/choyingw/M3-LRN">code</a>]
	 [<a href="works/M3-LRN/index.html">project page</a>]<br>
	 <!-- [<a href="https://www.youtube.com/watch?v=FQDTdpMPKxs">Youtube video</a>]<br> -->
	 <b>This work attains the state-of-the-art on 3D facial geometry prediction, including 3D facial alignment, face orientation estimation, and 3D face modeling.</b> 
	 </p> </li>

	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Scene Completeness-Aware Lidar Depth Completion for Driving Scenario <br> 
         <i>  <b>Cho-Ying Wu</b>, Ulrich Neumann</i><br> 
	       IEEE International Conference on Acoustics, Speech, & Signal Processing (<b>ICASSP</b>), 2021 <br>
	 [<a href="https://arxiv.org/abs/2003.06945">paper</a>]
	 [<a href="https://github.com/choyingw/SCADC-DepthCompletion">code</a>]
	 [<a href="works/SCADC/index.html">project page</a>]
	 [<a href="https://www.youtube.com/watch?v=FQDTdpMPKxs">Youtube video</a>]<br>
	 <b>This work is the first to attend scene-completeness issue of depth completion. We obtain both structured and accurate scene depth.</b> 
	 </p> </li>

	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Geometry-Aware Instance Segmentation with Disparity Maps <br> 
         <i>  <b>Cho-Ying Wu</b>, Xiaoyan Hu, Michael Happold, Qiangeng Xu, Ulrich Neumann</i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition Workshop Scalability in Autonomous Driving (<b>CVPRw</b>), 2020 <br>
	 [<a href="http://www-scf.usc.edu/~choyingw/works/GAIS-Net/WSAD/CVPRW_CameraReady.pdf">paper</a>]
	 [<a href="works/GAIS-Net/index.html">project page</a>]
	 [<a href="https://github.com/choyingw/GAIS-Net">code</a>]
	 [<a href="https://www.youtube.com/watch?v=QmzGAStQXOc">Youtube video</a>]<br>
	 <b> The first outdoor instacne segmentation that using disparity maps. Based on Mask-RCNN, we show that using multi-modality of geometric information can improve the performance.</b> 


	 </p> </li>


	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Grid-GCN for Fast and Scalable Point Cloud Learning <br> 
         <i>  Qiangeng Xu, Xudong Sun, <b>Cho-Ying Wu</b>, Panqu Wang, Ulrich Neumann</i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020 <br>
	 [<a href="https://arxiv.org/abs/1912.02984">paper</a>]
	 [<a href="https://github.com/ICpachong/Grid-GCN">code</a>]

	 </p> </li>
 
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Deep RGB-D Canonical Correlation Analysis for Sparse Depth Completion <br> 
         <i>  <b>Cho-Ying Wu*</b>, Yiqi Zhong*, Suya You, Ulrich Neumann (*Equal Contribution)</i><br> 
	       Neural Information Processing System (<b>NeurIPS</b>), 2019 <br>
	 [<a href="https://arxiv.org/abs/1906.08967">paper</a>]
	 [<a href="https://github.com/choyingw/CFCNet">code</a>]
	 [<a href="https://www.youtube.com/watch?v=6HCWipHkv60">Youtube video</a>]
	 [<a href="works/CFCNet/poster.pdf">poster</a>]<br>
	 <b> We study deep canonical correlation analysis for multi-modal fusion on depth completion and attain the SOTA performance when only few sparse measurements are available.</b> 

	 </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Salient Building Outline Enhancement and Extraction Using Iterative L0 Smoothing and Line Enhancing <br> 
         <i>  <b>Cho-Ying Wu</b>, Ulrich Neumann</i><br> 
	       IEEE International Conference on Image Processing (<b>ICIP</b>), 2019 <br>
	 [<a href="https://arxiv.org/abs/1906.02426">paper</a>]
	 [<a href="https://github.com/choyingw/BuildingOutline">code</a>]
	 [<a href="works/Building_Outline/All_GT.zip">groundtruth dataset</a>] 
	 [<a href="extra.html">additional results</a>]<br>
	 <b> Using iterative operation of L0-smoothing and enhancing, we can extract robust outlines for buildings.</b> 

	 </p> </li>

    <!--
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Nonconvex Surrogates for Robust Principal Component Analysis <br> 
         <i>  <b>Cho Ying Wu</b>, Jian Jiun Ding</i><br> 
	       submitted to IEEE International Symposium on Information Theory (<b>ISIT</b>), 2019 <br>
	 [<a href="">paper</a>]
	 [code] (Code will be released after accepted) 
	</p> </li>
	-->

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Efficient Multi-Domain Dictionary Learning with GANs<br> 
         <i>   <b>Cho-Ying Wu</b>, Ulrich Neumann </i><br> 
	     IEEE Global Signal and Information Processing, (<b>GlobalSIP</b>), 2019<br> (Oral)
	 [<a href="https://arxiv.org/abs/1811.00274">paper</a>]<br>
	 <b> This work learns multi-domain dictionary from GANs that improve the robustness of dictionary learning.</b> 
	  </font>
	 </p> </li>
	
	<!--
	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Advanced Optimization Approach for Low-Rank Models with Nonconvex Surrogates and Dual Momentum <br> 
         <i>   <b>Cho Ying Wu</b>, Jian Jiun Ding </i><br> 
	     <br>
	 [paper]
	 </font>
	 </p> </li>
	-->

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Occluded Face Recognition Using Low-rank Regression with Generalized Gradient Direction<br> 
	 <i>   <b>Cho-Ying Wu</b>, Jian Jiun Ding </i><br> 
             Pattern Recognition (<b>PR</b>), vol. 80, pp. 256â€“268, 2018. (Impact Factor: 5.898)<br>
	 [<a href="https://www.sciencedirect.com/science/article/pii/S0031320318301079">paper</a>]
	 [<a href="works/Face_GDHASLR.zip">code</a>]<br>
	 <b> A robust and efficient occluded face recognition framework that attains the SOTA, using the sparse and low-rank model.</b> 
	 </p> </li>

	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            A Fast Non-convex And Non-smooth Regularizer For Low Rank Matrix Completion<br> 
	 <i>   <b>Cho-Ying Wu</b>, Jian-Jiun Ding </i><br> 
             Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (<b>APSIPA-ASC</b>), 2017. <br>
	 [<a href="https://ieeexplore.ieee.org/document/8282052">paper</a>]
	 </p> </li>

	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
            Occlusion Pattern-based Dictionary For Robust Face Recognition<br> 
	 <i>   <b>Cho-Ying Wu</b>, Jian-Jiun Ding </i><br> 
             IEEE International Conference on Multimedia & Expo (<b>ICME</b>), 2016. <br>
	 [<a href="https://ieeexplore.ieee.org/document/7552982">paper</a>]
	 </p> </li>
	
</ul>


<!--
<ul style="list-style-type:none">		
        <li> <a href="https://cerg1.ugc.edu.hk/hkpfs/index.html"> 
	     <b>Hong Kong Ph.D. Fellowship</b> </a> (<b>Highest</b> scholarship for students study in Hong Kong), 2016-2020 </li>
        <li> <b>Top 10 Outstanding Students at SCUT</b> (<em><u>Rank 1st</u></em>, <b>highest</b> award for students at SCUT), 2016 </li>
	<li> <b>Google Excellence Scholarship</b> (1 of 58 winners in <b>China</b>), 2015 </li>
	<li> <b>Tencent Outstanding Scholarship</b> (the <b>only</b> undergraduate winner at SCUT), 2015 </li>
	<li> <b>National Scholarship</b> (<b>Highest</b> national wide scholarship for undergraduate students in China), 2013 </li>
	<li> <b>Gold Award</b> of Pan-Pearl-River-Delta University IT Project Competition in China, 2016 </li>
	<li> <b>First Prize</b> and <b>Best Practical Award</b> of University IT Project Competition in Guangdong Province, 2016 </li>
	<li> <b>First Prize</b> of Adolescents Science & Technology Innovation Contest in Hebei Province, 2011 </li>
</ul>
-->

<h2><font face="Arial"> Academic Activities </font></h2>
<ul style="list-style-type:none">
	
	<li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Reviewer </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
		 Journal: IEEE Access
		 Conference: ICIP 2019, ICIP 2020, ICIP 2021
	      </font> </p> 
         </li>
	
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
              <strong> Teaching Assistant </strong> <br> </font> </p> 
	      <p style="margin-left: 20px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
	       Computer Graphics, University of Southern California, Spring 2021<br>
	       Computer Graphics, University of Southern California, Fall 2020<br>
	       Database Systems, University of Southern California, Spring 2020<br>
	       Computer Graphics, University of Southern California, Fall 2019<br>
	       Data Structures and Object Oriented Design, University of Southern California, Spring 2019<br>
	       Advanced Digital Signal Processing, National Taiwan University, Spring 2017 <br>
	       Differential Equation, National Taiwan University, Fall 2016 <br>
	      </font> </p>
	 </li>
	
	

		
</body></html>

